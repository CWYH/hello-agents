import os
import ast
import json
from llm_client import HelloAgentsLLM
from dotenv import load_dotenv
from typing import Dict, Optional
from tools import ToolExecutor, search

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡ï¼Œå¤„ç†æ–‡ä»¶ä¸å­˜åœ¨å¼‚å¸¸
try:
    load_dotenv()
except FileNotFoundError:
    print("è­¦å‘Šï¼šæœªæ‰¾åˆ° .env æ–‡ä»¶ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡ã€‚")
except Exception as e:
    print(f"è­¦å‘Šï¼šåŠ è½½ .env æ–‡ä»¶æ—¶å‡ºé”™: {e}")

# --- 1. LLMå®¢æˆ·ç«¯å®šä¹‰ ---
# å‡è®¾ä½ å·²ç»æœ‰llm_client.pyæ–‡ä»¶ï¼Œé‡Œé¢å®šä¹‰äº†HelloAgentsLLMç±»

# --- 2. è§„åˆ’å™¨ (Planner) å®šä¹‰ ---
PLANNER_PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„AIè§„åˆ’ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·æå‡ºçš„å¤æ‚é—®é¢˜åˆ†è§£æˆä¸€ä¸ªç”±å¤šä¸ªç®€å•æ­¥éª¤ç»„æˆçš„è¡ŒåŠ¨è®¡åˆ’ã€‚
è¯·ç¡®ä¿è®¡åˆ’ä¸­çš„æ¯ä¸ªæ­¥éª¤éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ã€å¯æ‰§è¡Œçš„å­ä»»åŠ¡ï¼Œå¹¶ä¸”ä¸¥æ ¼æŒ‰ç…§é€»è¾‘é¡ºåºæ’åˆ—ã€‚
ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªPythonåˆ—è¡¨, å…¶ä¸­æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªæè¿°å­ä»»åŠ¡çš„å­—ç¬¦ä¸²ã€‚

é—®é¢˜: {question}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºä½ çš„è®¡åˆ’ï¼Œ```pythonä¸```ä½œä¸ºå‰åç¼€æ˜¯å¿…è¦çš„:
```python
["æ­¥éª¤1", "æ­¥éª¤2", "æ­¥éª¤3", ...]
```
"""

class Planner:
    def __init__(self, llm_client: HelloAgentsLLM):
        self.llm_client = llm_client

    def plan(self, question: str) -> list[str]:
        prompt = PLANNER_PROMPT_TEMPLATE.format(question=question)
        messages = [{"role": "user", "content": prompt}]
        
        print("--- æ­£åœ¨ç”Ÿæˆè®¡åˆ’ ---")
        response_text = self.llm_client.think(messages=messages) or ""
        print(f"âœ… è®¡åˆ’å·²ç”Ÿæˆ:\n{response_text}")
        
        try:
            plan_str = response_text.split("```python")[1].split("```")[0].strip()
            plan = ast.literal_eval(plan_str)
            return plan if isinstance(plan, list) else []
        except (ValueError, SyntaxError, IndexError) as e:
            print(f"âŒ è§£æè®¡åˆ’æ—¶å‡ºé”™: {e}")
            print(f"åŸå§‹å“åº”: {response_text}")
            return []
        except Exception as e:
            print(f"âŒ è§£æè®¡åˆ’æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return []

# --- 3. æ‰§è¡Œå™¨ (Executor) å®šä¹‰ ---
EXECUTOR_PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„AIæ‰§è¡Œä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸¥æ ¼æŒ‰ç…§ç»™å®šçš„è®¡åˆ’ï¼Œä¸€æ­¥æ­¥åœ°è§£å†³é—®é¢˜ã€‚
ä½ å°†æ”¶åˆ°åŸå§‹é—®é¢˜ã€å®Œæ•´çš„è®¡åˆ’ã€ä»¥åŠåˆ°ç›®å‰ä¸ºæ­¢å·²ç»å®Œæˆçš„æ­¥éª¤å’Œç»“æœã€‚
ä½ å¯ä»¥ä½¿ç”¨ä¸‹æ–¹çš„å·¥å…·åˆ—è¡¨è·å–æ‰€éœ€ä¿¡æ¯ï¼š
{tool_instructions}

ä½¿ç”¨å·¥å…·æ—¶ï¼Œè¯·è¾“å‡º JSONï¼š{{"tool": "å·¥å…·åç§°", "input": "å·¥å…·è¾“å…¥"}}ã€‚
å½“ä½ è·å¾—æœ€ç»ˆç­”æ¡ˆæ—¶ï¼Œä»…è¾“å‡ºç­”æ¡ˆæ–‡æœ¬ï¼Œä¸è¦å†è¾“å‡º JSON æˆ–é¢å¤–è§£é‡Šã€‚

# åŸå§‹é—®é¢˜:
{question}

# å®Œæ•´è®¡åˆ’:
{plan}

# å†å²æ­¥éª¤ä¸ç»“æœ:
{history}

# å½“å‰æ­¥éª¤:
{current_step}
"""

class Executor:
    def __init__(self, llm_client: HelloAgentsLLM, tool_executor: Optional[ToolExecutor] = None, max_tool_iterations: int = 5):
        self.llm_client = llm_client
        self.tool_executor = tool_executor
        self.max_tool_iterations = max_tool_iterations

    def _parse_tool_request(self, response_text: str) -> Optional[Dict[str, str]]:
        if not response_text:
            return None
        try:
            data = json.loads(response_text)
        except json.JSONDecodeError:
            try:
                data = ast.literal_eval(response_text)
            except (ValueError, SyntaxError):
                return None
        if isinstance(data, dict) and "tool" in data and "input" in data:
            tool_name = str(data["tool"]).strip()
            tool_input = str(data["input"])
            if tool_name:
                return {"tool": tool_name, "input": tool_input}
        return None

    def execute(self, question: str, plan: list[str]) -> str:
        history = ""
        final_answer = ""
        
        print("\n--- æ­£åœ¨æ‰§è¡Œè®¡åˆ’ ---")
        for i, step in enumerate(plan, 1):
            print(f"\n-> æ­£åœ¨æ‰§è¡Œæ­¥éª¤ {i}/{len(plan)}: {step}")
            tool_instructions = (
                self.tool_executor.getAvailableTools()
                if self.tool_executor and self.tool_executor.tools
                else "ï¼ˆå½“å‰æ— å¯ç”¨å·¥å…·ï¼‰"
            )
            prompt = EXECUTOR_PROMPT_TEMPLATE.format(
                question=question,
                plan=plan,
                history=history if history else "æ— ",
                current_step=step,
                tool_instructions=tool_instructions,
            )
            messages = [{"role": "user", "content": prompt}]
            tool_iterations = 0
            
            response_text = self.llm_client.think(messages=messages) or ""
            messages.append({"role": "assistant", "content": response_text})

            while self.tool_executor and tool_iterations < self.max_tool_iterations:
                tool_request = self._parse_tool_request(response_text)
                if not tool_request:
                    break

                tool_name = tool_request["tool"]
                tool_input = tool_request["input"]
                tool_func = self.tool_executor.getTool(tool_name)

                if not tool_func:
                    observation = f"é”™è¯¯ï¼šå·¥å…· '{tool_name}' æœªæ³¨å†Œã€‚"
                else:
                    print(f"ğŸ› ï¸ ä½¿ç”¨å·¥å…· '{tool_name}'ï¼Œè¾“å…¥: {tool_input}")
                    observation = tool_func(tool_input)
                    print(f"ğŸ“¥ å·¥å…· '{tool_name}' çš„è¾“å‡º: {observation}")

                history += f"æ­¥éª¤ {i}: {step}\nä½¿ç”¨å·¥å…· {tool_name} -> {observation}\n\n"
                tool_iterations += 1

                messages.append({"role": "user", "content": f"å·¥å…· '{tool_name}' çš„è¾“å‡º: {observation}"})
                response_text = self.llm_client.think(messages=messages) or ""
                messages.append({"role": "assistant", "content": response_text})

            history += f"æ­¥éª¤ {i}: {step}\nç»“æœ: {response_text}\n\n"
            final_answer = response_text
            print(f"âœ… æ­¥éª¤ {i} å·²å®Œæˆï¼Œç»“æœ: {final_answer}")

        return final_answer

# --- 4. æ™ºèƒ½ä½“ (Agent) æ•´åˆ ---
class PlanAndSolveAgent:
    def __init__(self, llm_client: HelloAgentsLLM, tool_executor: Optional[ToolExecutor] = None):
        self.llm_client = llm_client
        self.tool_executor = tool_executor or ToolExecutor()
        if not self.tool_executor.getTool("Search"):
            self.tool_executor.registerTool(
                "Search",
                "ä¸€ä¸ªç½‘é¡µæœç´¢å¼•æ“ã€‚å½“ä½ éœ€è¦å›ç­”å…³äºæ—¶äº‹ã€äº‹å®ä»¥åŠåœ¨ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°çš„ä¿¡æ¯æ—¶ï¼Œåº”ä½¿ç”¨æ­¤å·¥å…·ã€‚",
                search,
            )
        self.planner = Planner(self.llm_client)
        self.executor = Executor(self.llm_client, self.tool_executor)

    def run(self, question: str):
        print(f"\n--- å¼€å§‹å¤„ç†é—®é¢˜ ---\né—®é¢˜: {question}")
        plan = self.planner.plan(question)
        if not plan:
            print("\n--- ä»»åŠ¡ç»ˆæ­¢ --- \næ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„è¡ŒåŠ¨è®¡åˆ’ã€‚")
            return
        final_answer = self.executor.execute(question, plan)
        print(f"\n--- ä»»åŠ¡å®Œæˆ ---\næœ€ç»ˆç­”æ¡ˆ: {final_answer}")

# --- 5. ä¸»å‡½æ•°å…¥å£ ---
if __name__ == '__main__':
    try:
        llm_client = HelloAgentsLLM()
        agent = PlanAndSolveAgent(llm_client)
        # question = "ä¸€ä¸ªæ°´æœåº—å‘¨ä¸€å–å‡ºäº†15ä¸ªè‹¹æœã€‚å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡æ˜¯å‘¨ä¸€çš„ä¸¤å€ã€‚å‘¨ä¸‰å–å‡ºçš„æ•°é‡æ¯”å‘¨äºŒå°‘äº†5ä¸ªã€‚è¯·é—®è¿™ä¸‰å¤©æ€»å…±å–å‡ºäº†å¤šå°‘ä¸ªè‹¹æœï¼Ÿ"
        question = "åä¸ºæœ€æ–°çš„æ‰‹æœºæ˜¯å“ªä¸€æ¬¾ï¼Ÿå®ƒçš„ä¸»è¦å–ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿä»·æ ¼æ˜¯å¤šå°‘ï¼Ÿ"
        agent.run(question)
    except ValueError as e:
        print(e)
